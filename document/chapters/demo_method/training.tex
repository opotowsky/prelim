I am SCALE \cite{scale}, an experimental component!

I am \gls{ORIGEN-ARP} \cite{origen}, another experimental component!

I am \gls{GADRAS-DRF} \cite{gadras}, yet another experimental component!

This work begins by simulating the training and test sets described in ref
(cite Dayman). As with the previous work, this will be done using SCALE 6.2
\todo{cite}. Specifically, the ARP module of the activation and depletion code
ORIGEN was used. \todo{add deets and citations}

\todo{show table of training set space}
The parameters of the training set are defined as follows. A smaller burnup
than is typical for spent fuel from a commercial reactor is used in the
previous work likely because stolen fuel pins for weapons use would not likely
be at the end of their lifetime, as the plutonium of interest has decreased by
then. A truly i.i.d. training set would go beyond this, but this is purely for
demonstration with a single use case in mind. 

\todo{show table of test set space}
The previous work also used an external test set, designed to have values in
between the trained values of burnup. This is implemented in this study but it
is expected that cross-validation will better indicate the model performance.
More specifically, using k-fold cross-validation is a common method to use in
the application of machine learning to create more confidence in the resulting
model. \todo{either explain or cite cross validation next}

\subsection{Information Reduction}

This study evaluates the impact of randomly introduced error of varying amounts
on the ability of the algorithms to correctly predict the burnup. Thus, first
investigated are the three algorithms with no error introduced, and next with
the random errors applied uniformly to each nuclide vector. Since error in a
nuclide vector is not random, in fact it is systematic and dependent on a
number of known sources of uncertainty, the next study will introduce error by
limiting the nuclides to only those that can be measured with a gamma
spectrometer (future work).



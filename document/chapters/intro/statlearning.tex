While different machine learning algorithms and parameters will be
investigated, it is first important to determine if statistical methods can
overcome the inherent database deficiencies. Thus, this paper focuses on
probing the amount of information required to obtain realistic results.  This
can be best understood as the analgous real-world scenario. Although mass
spectroscopy techniques provide extremely accurate isotopic information, they
are time-consuming and more expensive. And although gamma spectroscopy can give
extremely fast results cheaply, it only measures certain radiological signals
and is influenced by many environmental factors, storage, and self-attenuation.

\todo{assumes previous section on fuel cycle sim} In the simulation and machine
learning paradigm, we need to determine what exactly is needed to train a
machine-learned model. Of interest to an entity trying to create a weapon is
partially irradiated fuel if they have plutonium separations capabilities or
any radioactive substance in the case of a dirty bomb. Addressing the former,
we used a set of simulations of spent nuclear fuel at different burnups and
cooling times. 

Can the algorithm overcome the deficiencies of gamma detection and still
provide useful results? Or does it need more information, e.g., exact
isotopics? Thus, ultimately, the goal is to answer the question \textit{How
does the ability to determine forensic-relevant spent nuclear fuel attributes
degrade as less information is available?}. 

But first, we must establish some baseline expectations of reactor parameter
prediction and algorithms to use.  This work is based off previous work on the
subject (cite Dayman) regarding machine learning performace with respect to
information reduction, and expands upon it by also evaluating a more advanced
machine learning algorithm: support vector regression. Below is a more in depth
discussion of nuclear forensics and how machine learning can contribute to this
research area. After that, an experimental design is outlined. Lastly, the
results are presented and discussed. 


%%%%%

Given imperfect data with varying amounts of uncertainty as well as the
required comparison to highly multidimensional databases with missing entries,
many have begun considering computational approaches to nuclear forensics
problems, such as the INDEPTH\todo{cite and discuss}

Another approach utilizes artificial intelligence to solve nuclear forensics
problems, such as implementing searching algorithms for database comparison and
machine learning for determining spent fuel characteristics \todo{cite
hungarian guy, viz guy, dayman paper}.  A variety of statistical and machine
learning tools have been used to characterize spent fuel by predicting
categories or labels (reactor type, fuel type) as well as predicting values
(burnup, initial enrichment, or cooling time) The former uses classification
algorithms and the latter uses regression algorithms. Many algorithms can be
applied to both cases.

A typical (supervised) machine learning workflow would take a set of training
data with labels or values inserted into some statistical learner, calculate
some objective, minimize or maximize that objective, and provide some model
based on that output. Then a test set (with known values) is provided to the
model so that its performance can be evaluated and finalized. After model
finalization, a user can provide a single instance and a value can be predicted
from that. \todo{insert ML schematic}

To obtain reliable models, one must 1. choose/create a training set carefully
and 2. study the impact of various algorithm parameters on the error. Many
algorithms are developed on an assumption that the training set will be
independent and identially distributed (i.i.d.). [Aside: there are ways to
handle skewed data sets] This is important so that the model does not overvalue
or overfit a certain area in the training space. Additionally, algorithm
performance (or error) can be optimized with respect to training set size,
number of features, or algorithm parameters (regularization terms, etc).  These
are known as diagnostic plots. When plotting the training and testing error
with respect to the number of instances, this is known as a learning curve.
When plotting these errors with respect to the number or features or algorithm
parameters, this is known as a validation curve. \todo{insert example
diagnostic plot?}

Algorithm choice is usually based on what is being predicted and intuition
regarding strengths and weaknesses.  For the sake of comparison (i.e. weak
validation), some machine learning approaches here are based on previous
work\todo{cite dayaman} while also extending to a more complex model via an
algorithm that is known to handle highly dimensional data sets well. Thus, this
paper investigates three regression algorithms: nearest neighbor, ridge, and
support vectors.


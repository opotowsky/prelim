Machine learning is a sub-field of \gls{AI} within the broad category of
computer science. The goal of \gls{AI} is to create computer systems that
respond to their environment according to some set of criteria or goal. For
example, self-driving vehicles have computers on board that learn to avoid
curbs and humans. It is common knowledge that the use of \gls{AI} has been
expanding at a rapid rate in recent years. News stories of major tech
companies' \gls{AI} advancements are frequent and news articles abound with
data on which jobs will be replaced with \gls{AI} in the near future. 

While its use has been increasing in the commercial sector, there is also much
anecdotal evidence to support the existence of a rapid increase of \gls{AI} use
in academic research across many disciplines beyond robotics. \gls{AI} systems
have been used in detection (e.g., fraud or spam), medical diagnostics, user
analysis (e.g., Netflix ratings), and a host of scientific disciplines that
have increasing amounts of multivariate data.

Much of the recent advances to the field of \gls{AI} have occured in the
statistical realm, which forgoes domain knowledge in favor of large data sets.
Thus, machine learning and statistical learning has become somewhat of a
separate field \cite{changingml}. Machine learning research focuses on the
underlying algorithms using mathematical optimization, methods for pattern
recognition, and computational statistics.  As an application, however, this
study is not concerned with computational time, but rather the ability to
correctly predict values and categories relevant to the nuclear forensics
mission. This restricts the relevancy of the algorithms to the underlying
theory and its impact on the resulting model's accuracy. 

Machine learning algorithms can be separated into two main categories:
unsupervised and supervised learning.  The former groups or interprets a set of
input data, predicting patterns or structures. The latter includes both the
input and output data, enabling the trained model to predict future outputs.
Broadly speaking, the unsupervised learning algorithms are designed for
clustering data sets or dimensionality reduction (i.e., determining some subset
or linear combination of features most relevant to the input data) of data
sets.  Supervised learning algorithms predict both discrete and continuous
values via classification and regression, respectively. Some algorithms can
perform both classification and regression, and neural networks can even be
modified to perform either supervised or unsupervised learning. 
%Additionally, various algorithms can be strung together, which is referred to
%as \textit{ensemble methods}. One common way of doing this is performing
%deimensionality reduction prior to supervised learning

\begin{figure}[!htb]
  \includegraphics[width=\linewidth]{./chapters/intro/SupervisedRegression.png}
  \caption{Schematic representing the workflow of a statistical learning regression algorithm}
  \label{fig:supervised}
\end{figure}

As shown in Figure \ref{fig:supervised}, a typical (supervised) machine
learning workflow begins with a training data set, which has a number of
\textit{instances}, or rows of observations.  Each instance has some
\textit{attributes}, also referred to as \textit{features}, and a label, which
can be a categorical label or discrete/continuous values.  

The training data are then inserted into a statistical learner; this calculates
some objective, minimizes or maximizes that objective, and provides some model.
This model is typically evaluated using a testing set that has the same set of
attributes and labels (but different instances). The comparison of what the
model predicts and the actual label gives the \textit{generalization error}.
Depending on the performance and application, the model may need improvement
from more training and/or some changes in the algorithm parameters. Once the
model is performing well enough and validated, it is finalized; then a user can
provide a single instance and a value can be predicted from that. 

This study performs regression tasks using supervised learning algorithms.
Differences among the underlying mathematics of the algorithms impact the
trained models.  Therefore the algorithms used in this study will be discussed
in Section \ref{sec:algs}. Next, model selection and assessment is covered in
Section \ref{sec:selectass}.  Evaluating and optimizing algorithm performance
is discussed in Section \ref{sec:optvalid}, as well as robustly comparing
different algorithms for validation.

\subsection{Algorithms for Statistical Learning}
\label{sec:algs}
\input{./chapters/litrev/algs}

\subsection{Model Selection and Assessment}
\label{sec:selectass}
\input{./chapters/litrev/selectass}

\subsection{Model Optimization and Validation}
\label{sec:optvalid}
\input{./chapters/litrev/optvalid}

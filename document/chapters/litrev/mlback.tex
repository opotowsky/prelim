Machine learning is a sub-field of \gls{AI} within the broad category of
computer science. The goal of \gls{AI} is to create computer systems that
respond to their environment according to some set of criteria or goal. For
example, self-driving vehicles have computers on board that learn to avoid
curbs and humans. While its use has been increasing in the commercial sector,
there is also much anecdotal evidence to support the existence of a rapid
increase of \gls{AI} use in academic research across many disciplines beyond
robotics. \gls{AI} systems have been used in detection (e.g., fraud or spam),
medical diagnostics, user analysis (e.g., Netflix ratings), and a host of
scientific disciplines that have increasing amounts of multivariate data.

Much of the recent advances to the field of \gls{AI} have occured in the
statistical realm, which forgoes domain knowledge in favor of large data sets.
Thus, machine learning and statistical learning have become somewhat separate
fields \cite{changingml}. Machine learning research focuses on the underlying
algorithms using mathematical optimization, methods for pattern recognition,
and computational statistics.  Since this work is only an application of
machine learning, there is no distinction made between the terminology.
Additionally, this study is not concerned with computational time, but rather
the ability to correctly predict values and categories relevant to the nuclear
forensics mission. This restricts the relevancy of the algorithms to the
underlying theory and its impact on the resulting model's accuracy. 

Machine learning algorithms can be separated into two main categories:
unsupervised and supervised learning.  The former groups or interprets a set of
input data, predicting patterns or structures. The latter includes both the
input and output data, enabling the trained model to predict future outputs.
Broadly speaking, the unsupervised learning algorithms are designed for
clustering data sets or dimensionality reduction (i.e., determining some subset
or linear combination of features most relevant to the input data) of data
sets.  Supervised learning algorithms predict both discrete and continuous
values via classification and regression, respectively. Some algorithms can
perform both classification and regression, and neural networks can even be
modified to perform either supervised or unsupervised learning. 
%Additionally, various algorithms can be strung together, which is referred to
%as \textit{ensemble methods}. One common way of doing this is performing
%deimensionality reduction prior to supervised learning
\\
\begin{figure}[!htb]
  \makebox[\textwidth][c]{\includegraphics[width=1.15\textwidth]{./chapters/intro/SupervisedRegression.png}}
  \caption{Schematic of Regression with Machine Learning}
  \label{fig:supervised}
\end{figure}

As shown in Figure \ref{fig:supervised}, a typical (supervised) machine
learning workflow begins with a training data set, which has a number of
\textit{instances}, or rows of observations.  Each instance has some
\textit{attributes}, also referred to as \textit{features}, and a label, which
can be a categorical label or discrete/continuous values.  

The training data are then inserted into a statistical learner; this calculates
some objective, minimizes or maximizes that objective, and provides some model.
This model is typically evaluated using a testing set that has the same set of
attributes and labels (but different instances). The comparison of what the
model predicts and the actual label gives the \textit{generalization error}.
Depending on the performance and application, the model may need improvement
from more training and/or some changes in the algorithm parameters. Once the
model is performing well enough and validated, it is finalized; then a user can
provide a single instance and a value can be predicted from that. 

This study performs regression tasks using supervised learning algorithms.
Differences among the underlying mathematics of the algorithms impact the
trained models.  Therefore the algorithms used in this study will be discussed
in Section \ref{sec:algs}. Next, model selection and assessment is covered in
Section \ref{sec:selectass}.  Evaluating and optimizing algorithm performance
is discussed in Section \ref{sec:optvalid}, as well as robustly comparing
different algorithms for validation.

\subsection{Algorithms for Statistical Learning}
\label{sec:algs}
\input{./chapters/litrev/algs}

\subsection{Model Selection and Assessment}
\label{sec:selectass}
\input{./chapters/litrev/selectass}

\subsection{Model Optimization and Validation}
\label{sec:optvalid}
\input{./chapters/litrev/optvalid}

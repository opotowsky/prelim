Machine learning is a sub-field of \gls{AI} within the broad category of
computer science. The goal of \gls{AI} is to create computer systems that
respond to their environment according to some set of criteria or goal
\cite{changingml}. For example, self-driving vehicles have computers on board
that learn to avoid curbs and humans. While its use has been increasing in the
commercial sector, there is also much anecdotal evidence to support the
existence of a rapid increase of \gls{AI} use in academic research across many
disciplines beyond robotics. \gls{AI} systems have been used in detection
(e.g., fraud or spam), medical diagnostics, user analysis (e.g., Netflix
ratings), and a host of scientific disciplines that have increasing amounts of
multivariate data.

Machine learning research focuses on the underlying algorithms using
mathematical optimization, methods for pattern recognition, and computational
statistics.  Much of the recent advances to the field of \gls{AI} have occured
in the statistical realm, which forgoes domain knowledge in favor of large data
sets.  In this work, there is no distinction made between the terminology of
machine learning and statistics.  Additionally, this study is not concerned
with computational time, but rather the ability to correctly predict values and
categories relevant to the nuclear forensics mission. This restricts the
relevancy of the algorithms to the underlying theory and its impact on the
resulting model's accuracy. 

Machine learning algorithms can be separated into two main categories:
unsupervised and supervised learning.  The former groups or interprets a set of
input data, predicting patterns or structures. The latter includes both the
input and output data, enabling the trained model to predict future outputs.
Broadly speaking, the unsupervised learning algorithms are designed for
clustering data sets or dimensionality reduction (i.e., determining some subset
or linear combination of features most relevant to the input data) of data
sets.  Supervised learning algorithms predict both discrete and continuous
values via classification and regression, respectively. Some algorithms can
perform both classification and regression, and neural networks can even be
modified to perform either supervised or unsupervised
learning.\cite{elements_stats} 
\\
\begin{figure}[!htb]
  \makebox[\textwidth][c]{\includegraphics[width=1.15\textwidth]{./chapters/intro/SupervisedRegression.png}}
  \caption{Schematic of Regression with Machine Learning}
  \label{fig:supervised}
\end{figure}

As shown in Figure \ref{fig:supervised}, a typical (supervised) machine
learning workflow begins with a training data set, which has a number of
\textit{instances}, or rows of \textit{observations}.  Each instance has some
\textit{attributes}, also referred to as \textit{features}. It also has a
\textit{label}, which can be a categorical label or discrete/continuous values.  

The training data are then inserted into a statistical learner; this calculates
some objective, minimizes or maximizes that objective, and provides some model.
This model can be evaluated using a testing set that has the same set of
features and labels (but different instances). The comparison of what the
model predicts and the actual label gives the \textit{generalization error}.
Depending on the performance and application, the model may need improvement
from more training and/or some changes in the algorithm parameters. Once the
model is performing well enough and validated, it is finalized; then a user can
provide a single instance and a value can be predicted from that. 

This study performs regression tasks using supervised learning algorithms.
Differences among the structure underlying mathematics of the algorithms impact the
trained models.  Therefore, the algorithms used in this study will be discussed
in Section \ref{sec:algs}. Next, model selection and assessment is covered in
Section \ref{sec:selectass}.  Evaluating and optimizing algorithm performance
is discussed in Section \ref{sec:optvalid}, as well as robustly comparing
different algorithms for validation.

\subsection{Algorithms for Statistical Learning}
\label{sec:algs}
\input{./chapters/litrev/algs}

\subsection{Model Selection and Assessment}
\label{sec:selectass}
\input{./chapters/litrev/selectass}

\subsection{Model Optimization and Validation}
\label{sec:optvalid}
\input{./chapters/litrev/optvalid}

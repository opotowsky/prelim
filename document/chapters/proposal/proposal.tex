\chapter{Research Proposal}
\label{ch:proposal}

Prop intro

Section \ref{sec:summary} presents how the initial results guided the next
steps for future experiments, which are discussed in Section
\ref{sec:newtrain}. Steps taken towards model comparison (or even comparison
against non-statistical methods) are shown in \ref{sec:compare}. \todo{update
me if necessary} Finally, hypotheses are listed in Section
\ref{sec:hypotheses}.

\section{Follow-up Tasks}
\label{sec:tasks}

\subsection{Expanding the Training Set Space}
\label{sec:newtrain}

The preliminary results indicate the models were severely underfitted.

To obtain reliable models, one must both choose or create a training set
carefully and study the impact of various algorithm parameters on the error.
Many algorithms are developed on an assumption that the training set will be
independent and identially distributed (i.i.d.). This is important so that the
model does not overvalue or overfit a certain area in the training space. The
testing error can therefore be tabulated with respect to training set size,
number of features, or algorithm parameters (regularization terms, etc). The
results are broadly known as diagnostic plots. 

The next step is to provide a larger, more diverse training set to the
algorithms so they could predict better when faced with new instances.  Dayman
training/test set -> sfcompo-like sims and testing set

\subsection{Comparing Different Models}
\label{sec:compare}

Will I have prob density for prelim? Prob not? If yes move elsewhere.

\section{Summary of Experiments}
\label{sec:summary}

Table?

\section{Hypotheses}
\label{sec:hypotheses}

I hypothesize!


